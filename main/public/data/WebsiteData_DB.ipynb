{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import to AWS DB\n",
    "\n",
    "1) Run `CalculateEverything` in the `InternationalityIndex.InternationalityCalculations.py`\n",
    "\n",
    "2) Copy the output xlsx file in the same folder as this notebook.\n",
    "\n",
    "3) Edit the first two rows in the following cell and run it.\n",
    "\n",
    "4) Copy all files from the AWS_Import directory using WinSCP\n",
    "\n",
    "    a. Connect to AWS EC2 IDEA (ubuntu@ec2-18-188-88-0.us-east-2.compute.amazonaws.com)\n",
    "    \n",
    "    b. Copy csv files from the `AWS_Import` directory to `\\home\\ubuntu\\db-admin\\csv`\n",
    "    \n",
    "5) Using Putty, run the import to AWS\n",
    "\n",
    "    a. Connect to AWS EC2 IDEA (ubuntu@ec2-18-188-88-0.us-east-2.compute.amazonaws.com)\n",
    "    \n",
    "    b. Go to `db-admin` directory\n",
    "    \n",
    "    c. run: `psql --host=science-internationality-dbinstance.c3aa5fkeiz2h.us-east-2.rds.amazonaws.com --port=5432 --username=root --password --dbname=scienceInternationalitydb -f drop_generate_schema.sql`\n",
    "    \n",
    "    d. run: `psql --host=science-internationality-dbinstance.c3aa5fkeiz2h.us-east-2.rds.amazonaws.com --port=5432 --username=root --password --dbname=scienceInternationalitydb -f psql-import-csvs.txt`\n",
    "    \n",
    "    \n",
    "In case of problems check\n",
    "    a. Variable names - from the original excel in additionalData, through the table schema in drop_generate_schema.sql to variable names in psql-import-csvs.txt\n",
    "    \n",
    "    b. Data validity in CSVs.\n",
    "    \n",
    "    c. Also prisma query in fetcher.js should contain valid variable names! If they change, prisma should be rerun as follows:\n",
    "        1. docker-compose down\n",
    "        2. change the datamodel.yml\n",
    "        3. docker-compose up -d prisma\n",
    "        4. prisma deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topData = '20181106_AllFieldsCountriesMethods_TOP.xlsx' ## OUTPUT OF CalculateEverything() in InternationalityIndex.InternationalityCalculations.py\n",
    "bottomData = '20181128_AllFieldsCountriesMethods_bot.xlsx'\n",
    "additionalData = 'populateAmazon.xlsx'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "tops = pd.read_excel(topData,index_col=[0,1,2,3]).reset_index()\n",
    "bottoms = pd.read_excel(bottomData,index_col=[0,1,2,3]).reset_index()\n",
    "bottoms = bottoms[bottoms.Field != 'All']\n",
    "df = pd.concat([tops,bottoms],ignore_index=True)\n",
    "\n",
    "countries = pd.read_excel(additionalData,sheet_name='country')\n",
    "index = pd.read_excel(additionalData,sheet_name='index',index=False)\n",
    "\n",
    "merged = pd.merge(df,countries,how='left',left_on='Country',right_on='name').loc[:,['country_code','Field','Method','Period','Internationality']]\n",
    "merged.columns = index.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter displayed globalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "jrnThreshold = 30\n",
    "fields = merged.field_code.unique()\n",
    "\n",
    "\n",
    "def getDocsJournalsForField(field,conn):\n",
    "\n",
    "    if field == 'All':\n",
    "        query ='''\n",
    "        SELECT\n",
    "       c.name as Country,\n",
    "       p.name as Year,\n",
    "       Sum(A.Articles) AS Documents,\n",
    "       Count(A.Articles) as Journals\n",
    "\n",
    "        FROM ArticleCountries as A\n",
    "        INNER JOIN countries c on A.FacetID = c.ID\n",
    "        INNER JOIN periods p on A.PeriodID = p.ID\n",
    "        INNER JOIN issns i on A.ISSNID = i.ID\n",
    "        GROUP BY Country,Year\n",
    "\n",
    "        '''\n",
    "    else:\n",
    "        query = '''\n",
    "        SELECT\n",
    "       c.name as Country,\n",
    "       p.name as Year,\n",
    "       Sum(A.Articles) AS Documents,\n",
    "       Count(A.Articles) as Journals\n",
    "\n",
    "        FROM ArticleCountries as A\n",
    "        INNER JOIN countries c on A.FacetID = c.ID\n",
    "        INNER JOIN periods p on A.PeriodID = p.ID\n",
    "        INNER JOIN issns i on A.ISSNID = i.ID\n",
    "        WHERE i.{} = 1\n",
    "        GROUP BY Country,Year\n",
    "        \n",
    "        '''.format(field)\n",
    "\n",
    "    df = pd.read_sql_query(query,conn)\n",
    "    df['field'] = field\n",
    "    return df\n",
    "\n",
    "#conn = sqlite3.connect('D:/Dropbox/Python/AllScopusJournals/180802_1611_AllJournals_ArReCp_2001_2017.sqlite')\n",
    "conn = sqlite3.connect('C:/Users/vitekzkytek/Dropbox/Python/AllScopusJournals/180802_1611_AllJournals_ArReCp_2001_2017.sqlite')\n",
    "dfs =[]\n",
    "\n",
    "for field in fields:\n",
    "    dfs.append(getDocsJournalsForField(field,conn))\n",
    "\n",
    "filters = pd.concat(dfs).merge(countries.loc[:,['country_code','name']],left_on='Country',right_on='name').drop('name',axis=1)\n",
    "filters['include'] = np.where(filters['Journals'] >= jrnThreshold, True, False)\n",
    "filters.Year = pd.to_numeric(filters.Year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = merged.merge(filters,left_on=['country_code','field_code','period'],right_on=['country_code','field','Year'],how='left')\n",
    "merged = merged[merged['include'] == True]\n",
    "merged = merged.drop(['Documents','Journals','field','Country','Year','include'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate group averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avgs = [merged]\n",
    "def calcGroupAverage(mergedDF,countriesDF,dimension,new_country_codes):\n",
    "    df = mergedDF.merge(countriesDF,on='country_code',how='left').set_index(keys=['country_code','field_code','method_code','period'])\n",
    "    df = df[['value',dimension]]\n",
    "    g = df.groupby(['field_code','method_code','period',dimension]).mean().reset_index()\n",
    "    g['country_code'] = g[dimension].map(new_country_codes,na_action='ignore')\n",
    "    return g.drop(dimension,axis=1)[mergedDF.columns].dropna()\n",
    "\n",
    "cntrs = [countries]\n",
    "def appendToCountries(countries,d):\n",
    "    l = [{'country_code':d[key],'name':key,'Type':'aggregate'} for key in d.keys()]\n",
    "    df = pd.DataFrame(l)\n",
    "    return df\n",
    "\n",
    "#regions\n",
    "d = {'North America':'_NAmer',\n",
    "     'East Asia':'_EAsia',\n",
    "     'Europe':'_Europe',\n",
    "     'South Asia':'_SAsia',\n",
    "     'Pacific':'_Pac',\n",
    "     'South America':'_SAmer',\n",
    "     'Central Asia':'_CAsia',\n",
    "     'Middle East':'_MEast',\n",
    "     'Sub-Saharan Africa':'_SSAfr',\n",
    "     'North Africa':'_NAfr'\n",
    "    }\n",
    "avgs.append(calcGroupAverage(merged,countries, 'region',d))\n",
    "cntrs.append(appendToCountries(countries,d))\n",
    "\n",
    "\n",
    "# Income Level\n",
    "d = {'Upper middle income':'_UMI','High income':'_HI','Lower middle income':'_LMI','Low income':'_LI'}\n",
    "avgs.append(calcGroupAverage(merged,countries, 'incomelevel',d))\n",
    "cntrs.append(appendToCountries(countries,d))\n",
    "\n",
    "\n",
    "#EU\n",
    "d = {'EU-15':'_EU15','EU-13':'_EU13'}\n",
    "avgs.append(calcGroupAverage(merged,countries, 'eu_sub',d))\n",
    "cntrs.append(appendToCountries(countries,d))\n",
    "\n",
    "# whole EU\n",
    "d = {'EU':'_EU'}\n",
    "avgs.append(calcGroupAverage(merged,countries, 'eu',d))\n",
    "cntrs.append(appendToCountries(countries,d))\n",
    "\n",
    "\n",
    "#OECD\n",
    "d = {'OECD':'_OECD'}\n",
    "avgs.append(calcGroupAverage(merged,countries, 'oecd',d))\n",
    "cntrs.append(appendToCountries(countries,d))\n",
    "\n",
    "\n",
    "#IMF 2003\n",
    "d = {\n",
    "    'Advanced Countries':'_ADV',\n",
    "    'Developing Countries':'_DEV',\n",
    "    'Transition Countries':'_TRA'\n",
    "}\n",
    "avgs.append(calcGroupAverage(merged,countries, 'imf2003',d))\n",
    "cntrs.append(appendToCountries(countries,d))\n",
    "\n",
    "# World\n",
    "world = merged.set_index(['country_code','field_code','method_code','period']).unstack('country_code').mean(axis=1).rename('value').reset_index()\n",
    "world['country_code'] = '_AV'\n",
    "world = world[merged.columns]\n",
    "avgs.append(world)\n",
    "cntrs.append(appendToCountries(countries,{'World':'_AV'}))\n",
    "\n",
    "merged = pd.concat(avgs,ignore_index=True)\n",
    "countries = pd.concat(cntrs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries.to_csv('AWS_Import/country.csv',index=False)\n",
    "\n",
    "method = pd.read_excel(additionalData,sheet_name='method').to_csv('AWS_Import/method.csv',index=False)\n",
    "field = pd.read_excel(additionalData,sheet_name='field').to_csv('AWS_Import/field.csv',index=False)\n",
    "merged.to_csv('AWS_Import/index.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JSONs with controlling data\n",
    "\n",
    "1. Run both cells in the notebook\n",
    "\n",
    "2. Copy the file `controls_data.js` from this notebooks directory into `main/public/javascripts/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_methods = pd.read_excel('populateAmazon.xlsx',sheet_name='method',index_col='method_code')\n",
    "df_methods = df_methods.loc[['euclid','weightGini','localShare','shareEnglish','top3','GiniSimpson'],:]\n",
    "df_fields = pd.read_excel('populateAmazon.xlsx',sheet_name='field',index_col='field_code')\n",
    "df_countries = pd.read_excel('populateAmazon.xlsx',sheet_name='country',index_col='country_code')\n",
    "df_countries = countries.set_index('country_code')[df_countries.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_aggr = df_countries.loc[df_countries.Type == 'aggregate','name'].reset_index().rename(columns={'country_code':'id','name':'text'}).to_dict(orient='records')\n",
    "d_cntrs = df_countries.loc[df_countries.Type == 'country','name'].reset_index().rename(columns={'country_code':'id','name':'text'}).sort_values('text').to_dict(orient='records')\n",
    "d_countries = {'results':[{'text':'Country Groups','children':d_aggr},{'text':'Countries','children':d_cntrs}],'pagination':{'more':True}}\n",
    "\n",
    "d_tops = df_fields.loc[df_fields.level == 'TOP','name'].reset_index().rename(columns={'field_code':'id','name':'text'}).to_dict(orient='records')\n",
    "d_bottoms = df_fields.loc[df_fields.level == 'BOT','name'].reset_index().rename(columns={'field_code':'id','name':'text'}).to_dict(orient='records')\n",
    "d_fields = {'results':[{'text':'Broad Subject clusters','children':d_tops},{'text':'Major Subject Areas','children':d_bottoms}],'pagination':{'more':True}}\n",
    "\n",
    "d_methods = df_methods.reset_index().rename(columns={'method_code':'id','name':'text'}).to_dict(orient='records')\n",
    "d_methods = {'results':d_methods,'pagination':{'more':True}}\n",
    "\n",
    "d = {'methods': d_methods,'fields':d_fields,'countries':d_countries}\n",
    "\n",
    "import json\n",
    "s = 'var controllers = %s' % (json.dumps(d))\n",
    "\n",
    "with open(\"controls_data.js\", \"w\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
